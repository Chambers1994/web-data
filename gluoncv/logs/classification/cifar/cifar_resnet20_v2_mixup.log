INFO:root:Namespace(batch_size=128, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.1, lr_decay_epoch='100,150', lr_decay_period=0, mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=220, num_gpus=1, num_workers=2, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0001)
[17:13:12] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.219984 val=0.474300 loss=1.910961 time: 15.101352
INFO:root:[Epoch 1] train=0.199940 val=0.648100 loss=1.642014 time: 14.884104
INFO:root:[Epoch 2] train=0.186867 val=0.640800 loss=1.526498 time: 14.774698
INFO:root:[Epoch 3] train=0.178819 val=0.734600 loss=1.504102 time: 14.762219
INFO:root:[Epoch 4] train=0.174447 val=0.726500 loss=1.433132 time: 14.821633
INFO:root:[Epoch 5] train=0.170522 val=0.740200 loss=1.382950 time: 15.704395
INFO:root:[Epoch 6] train=0.167885 val=0.792100 loss=1.390420 time: 14.859175
INFO:root:[Epoch 7] train=0.165345 val=0.714300 loss=1.355076 time: 14.695740
INFO:root:[Epoch 8] train=0.163289 val=0.764300 loss=1.316095 time: 14.779147
INFO:root:[Epoch 9] train=0.160482 val=0.793800 loss=1.289431 time: 14.959372
INFO:root:[Epoch 10] train=0.159384 val=0.774200 loss=1.302040 time: 14.921969
INFO:root:[Epoch 11] train=0.158153 val=0.822500 loss=1.293733 time: 15.265086
INFO:root:[Epoch 12] train=0.156624 val=0.815400 loss=1.278848 time: 14.739926
INFO:root:[Epoch 13] train=0.155051 val=0.802700 loss=1.270059 time: 14.659199
INFO:root:[Epoch 14] train=0.154110 val=0.788200 loss=1.260478 time: 15.249554
INFO:root:[Epoch 15] train=0.152851 val=0.798600 loss=1.289134 time: 14.787379
INFO:root:[Epoch 16] train=0.150851 val=0.819900 loss=1.249383 time: 15.781646
INFO:root:[Epoch 17] train=0.150383 val=0.800300 loss=1.231833 time: 14.746151
INFO:root:[Epoch 18] train=0.150674 val=0.814000 loss=1.255898 time: 14.753653
INFO:root:[Epoch 19] train=0.148259 val=0.823600 loss=1.213353 time: 15.006550
INFO:root:[Epoch 20] train=0.148217 val=0.787600 loss=1.228911 time: 14.895544
INFO:root:[Epoch 21] train=0.148509 val=0.839800 loss=1.224008 time: 15.181250
INFO:root:[Epoch 22] train=0.147684 val=0.818800 loss=1.207910 time: 14.951233
INFO:root:[Epoch 23] train=0.146389 val=0.831500 loss=1.217365 time: 14.740257
INFO:root:[Epoch 24] train=0.146559 val=0.841600 loss=1.199268 time: 14.839408
INFO:root:[Epoch 25] train=0.145138 val=0.838200 loss=1.179004 time: 15.232886
INFO:root:[Epoch 26] train=0.145280 val=0.825800 loss=1.209685 time: 14.748550
INFO:root:[Epoch 27] train=0.145396 val=0.836300 loss=1.232926 time: 14.655221
INFO:root:[Epoch 28] train=0.144640 val=0.814900 loss=1.211159 time: 14.873923
INFO:root:[Epoch 29] train=0.143701 val=0.831500 loss=1.199686 time: 15.087946
INFO:root:[Epoch 30] train=0.144182 val=0.798100 loss=1.219671 time: 14.960896
INFO:root:[Epoch 31] train=0.143832 val=0.843000 loss=1.203094 time: 15.179673
INFO:root:[Epoch 32] train=0.142355 val=0.847500 loss=1.174924 time: 15.372765
INFO:root:[Epoch 33] train=0.141982 val=0.823900 loss=1.172471 time: 15.200019
INFO:root:[Epoch 34] train=0.141278 val=0.846600 loss=1.155418 time: 15.371906
INFO:root:[Epoch 35] train=0.143582 val=0.849300 loss=1.211643 time: 14.899330
INFO:root:[Epoch 36] train=0.142119 val=0.784800 loss=1.163249 time: 15.162902
INFO:root:[Epoch 37] train=0.141065 val=0.835500 loss=1.178737 time: 15.000057
INFO:root:[Epoch 38] train=0.141072 val=0.840300 loss=1.184038 time: 14.720481
INFO:root:[Epoch 39] train=0.139508 val=0.868600 loss=1.156918 time: 14.994824
INFO:root:[Epoch 40] train=0.140965 val=0.835900 loss=1.179237 time: 15.715356
INFO:root:[Epoch 41] train=0.139240 val=0.813300 loss=1.152530 time: 15.451281
INFO:root:[Epoch 42] train=0.139046 val=0.855800 loss=1.139560 time: 14.763704
INFO:root:[Epoch 43] train=0.139008 val=0.846300 loss=1.160934 time: 14.859030
INFO:root:[Epoch 44] train=0.139712 val=0.814700 loss=1.167772 time: 15.191105
INFO:root:[Epoch 45] train=0.140154 val=0.845600 loss=1.179723 time: 15.123049
INFO:root:[Epoch 46] train=0.139096 val=0.855900 loss=1.148226 time: 15.469343
INFO:root:[Epoch 47] train=0.138657 val=0.866800 loss=1.167724 time: 15.031309
INFO:root:[Epoch 48] train=0.137954 val=0.867800 loss=1.138050 time: 15.770866
INFO:root:[Epoch 49] train=0.139184 val=0.843600 loss=1.162607 time: 14.916794
INFO:root:[Epoch 50] train=0.136230 val=0.849900 loss=1.106473 time: 15.872637
INFO:root:[Epoch 51] train=0.137211 val=0.859800 loss=1.148473 time: 14.913531
INFO:root:[Epoch 52] train=0.137446 val=0.856500 loss=1.153933 time: 14.755675
INFO:root:[Epoch 53] train=0.137236 val=0.843700 loss=1.137845 time: 14.686361
INFO:root:[Epoch 54] train=0.137231 val=0.870800 loss=1.153182 time: 15.097970
INFO:root:[Epoch 55] train=0.139346 val=0.860000 loss=1.199794 time: 14.998982
INFO:root:[Epoch 56] train=0.137506 val=0.859800 loss=1.141000 time: 15.067872
INFO:root:[Epoch 57] train=0.135684 val=0.854500 loss=1.126134 time: 15.030007
INFO:root:[Epoch 58] train=0.137189 val=0.849400 loss=1.152635 time: 14.786744
INFO:root:[Epoch 59] train=0.137727 val=0.867300 loss=1.161070 time: 15.678262
INFO:root:[Epoch 60] train=0.135821 val=0.872200 loss=1.158931 time: 15.274458
INFO:root:[Epoch 61] train=0.136692 val=0.836500 loss=1.139115 time: 15.645631
INFO:root:[Epoch 62] train=0.137942 val=0.844100 loss=1.167325 time: 14.886459
INFO:root:[Epoch 63] train=0.136304 val=0.865300 loss=1.148879 time: 14.915638
INFO:root:[Epoch 64] train=0.137101 val=0.871900 loss=1.155678 time: 15.338199
INFO:root:[Epoch 65] train=0.135834 val=0.870900 loss=1.124886 time: 14.994997
INFO:root:[Epoch 66] train=0.136569 val=0.855900 loss=1.153872 time: 14.719587
INFO:root:[Epoch 67] train=0.134211 val=0.856700 loss=1.103054 time: 15.009375
INFO:root:[Epoch 68] train=0.134971 val=0.838200 loss=1.131587 time: 15.115866
INFO:root:[Epoch 69] train=0.134739 val=0.870600 loss=1.116545 time: 15.679743
INFO:root:[Epoch 70] train=0.136217 val=0.864900 loss=1.156960 time: 14.848518
INFO:root:[Epoch 71] train=0.134277 val=0.861600 loss=1.099352 time: 15.462378
INFO:root:[Epoch 72] train=0.135089 val=0.854800 loss=1.138187 time: 15.054418
INFO:root:[Epoch 73] train=0.134974 val=0.856300 loss=1.120995 time: 15.621205
INFO:root:[Epoch 74] train=0.135419 val=0.833900 loss=1.149622 time: 15.737932
INFO:root:[Epoch 75] train=0.134732 val=0.870300 loss=1.121187 time: 15.613596
INFO:root:[Epoch 76] train=0.133200 val=0.873800 loss=1.097539 time: 15.542464
INFO:root:[Epoch 77] train=0.135268 val=0.868400 loss=1.147909 time: 14.972242
INFO:root:[Epoch 78] train=0.135094 val=0.865900 loss=1.122920 time: 15.322447
INFO:root:[Epoch 79] train=0.134793 val=0.854300 loss=1.149298 time: 15.078204
INFO:root:[Epoch 80] train=0.134995 val=0.863900 loss=1.132363 time: 14.826936
INFO:root:[Epoch 81] train=0.136684 val=0.837300 loss=1.162513 time: 15.677314
INFO:root:[Epoch 82] train=0.135730 val=0.857100 loss=1.133312 time: 14.868859
INFO:root:[Epoch 83] train=0.136649 val=0.875000 loss=1.164277 time: 15.033348
INFO:root:[Epoch 84] train=0.135051 val=0.826500 loss=1.151876 time: 14.912092
INFO:root:[Epoch 85] train=0.134558 val=0.827600 loss=1.151129 time: 14.783340
INFO:root:[Epoch 86] train=0.134664 val=0.850500 loss=1.126153 time: 15.454433
INFO:root:[Epoch 87] train=0.135684 val=0.796100 loss=1.159565 time: 14.847615
INFO:root:[Epoch 88] train=0.136104 val=0.842900 loss=1.170181 time: 15.032524
INFO:root:[Epoch 89] train=0.135035 val=0.863800 loss=1.145352 time: 14.893025
INFO:root:[Epoch 90] train=0.134498 val=0.858400 loss=1.146818 time: 15.369561
INFO:root:[Epoch 91] train=0.133493 val=0.833000 loss=1.106820 time: 14.932049
INFO:root:[Epoch 92] train=0.133825 val=0.874900 loss=1.111523 time: 14.736640
INFO:root:[Epoch 93] train=0.134419 val=0.839300 loss=1.121734 time: 14.789930
INFO:root:[Epoch 94] train=0.133236 val=0.857800 loss=1.119608 time: 14.821089
INFO:root:[Epoch 95] train=0.134528 val=0.864800 loss=1.145158 time: 14.674920
INFO:root:[Epoch 96] train=0.132528 val=0.878900 loss=1.102543 time: 14.759615
INFO:root:[Epoch 97] train=0.132263 val=0.871000 loss=1.088177 time: 15.222957
INFO:root:[Epoch 98] train=0.133930 val=0.826100 loss=1.124742 time: 15.405942
INFO:root:[Epoch 99] train=0.134342 val=0.855500 loss=1.145154 time: 15.279662
INFO:root:[Epoch 100] train=0.124133 val=0.900700 loss=1.059233 time: 15.444290
INFO:root:[Epoch 101] train=0.120360 val=0.905000 loss=1.041066 time: 14.835357
INFO:root:[Epoch 102] train=0.120377 val=0.897600 loss=1.029700 time: 15.213935
INFO:root:[Epoch 103] train=0.119751 val=0.904700 loss=1.041948 time: 15.139750
INFO:root:[Epoch 104] train=0.120525 val=0.908000 loss=1.055370 time: 15.044913
INFO:root:[Epoch 105] train=0.118799 val=0.905300 loss=1.042005 time: 15.247775
INFO:root:[Epoch 106] train=0.118488 val=0.905900 loss=1.034440 time: 15.210183
INFO:root:[Epoch 107] train=0.118210 val=0.905900 loss=1.037842 time: 15.044183
INFO:root:[Epoch 108] train=0.119657 val=0.912600 loss=1.064989 time: 14.979711
INFO:root:[Epoch 109] train=0.117555 val=0.908400 loss=1.026098 time: 15.059148
INFO:root:[Epoch 110] train=0.115384 val=0.911400 loss=0.987807 time: 15.028400
INFO:root:[Epoch 111] train=0.117131 val=0.912300 loss=1.027392 time: 14.792361
INFO:root:[Epoch 112] train=0.115152 val=0.908500 loss=1.002257 time: 15.443989
INFO:root:[Epoch 113] train=0.117739 val=0.910200 loss=1.039795 time: 14.793351
INFO:root:[Epoch 114] train=0.115804 val=0.910000 loss=1.010486 time: 14.857684
INFO:root:[Epoch 115] train=0.115158 val=0.911400 loss=1.013286 time: 15.208246
INFO:root:[Epoch 116] train=0.115009 val=0.914400 loss=1.005003 time: 15.050803
INFO:root:[Epoch 117] train=0.114779 val=0.909300 loss=1.002070 time: 15.628861
INFO:root:[Epoch 118] train=0.113810 val=0.910300 loss=0.995762 time: 15.180068
INFO:root:[Epoch 119] train=0.113512 val=0.906700 loss=0.972673 time: 14.747203
INFO:root:[Epoch 120] train=0.115422 val=0.908500 loss=0.994536 time: 14.838872
INFO:root:[Epoch 121] train=0.114435 val=0.913000 loss=0.998187 time: 15.357965
INFO:root:[Epoch 122] train=0.117240 val=0.912400 loss=1.034406 time: 15.033865
INFO:root:[Epoch 123] train=0.113298 val=0.911900 loss=0.985424 time: 15.163964
INFO:root:[Epoch 124] train=0.115861 val=0.907600 loss=1.026399 time: 15.017053
INFO:root:[Epoch 125] train=0.116451 val=0.912000 loss=1.041463 time: 14.768322
INFO:root:[Epoch 126] train=0.113385 val=0.906000 loss=0.999859 time: 15.018807
INFO:root:[Epoch 127] train=0.114089 val=0.911800 loss=1.014327 time: 15.209992
INFO:root:[Epoch 128] train=0.115252 val=0.910600 loss=1.018971 time: 15.103325
INFO:root:[Epoch 129] train=0.113683 val=0.909300 loss=1.006541 time: 14.988545
INFO:root:[Epoch 130] train=0.112326 val=0.912400 loss=0.984210 time: 15.046283
INFO:root:[Epoch 131] train=0.113566 val=0.914400 loss=1.004499 time: 14.895084
INFO:root:[Epoch 132] train=0.113758 val=0.916600 loss=0.999506 time: 15.700491
INFO:root:[Epoch 133] train=0.115106 val=0.915500 loss=1.026432 time: 15.188863
INFO:root:[Epoch 134] train=0.113893 val=0.914600 loss=1.008928 time: 16.164673
INFO:root:[Epoch 135] train=0.111731 val=0.914100 loss=0.973463 time: 15.693808
INFO:root:[Epoch 136] train=0.115783 val=0.914300 loss=1.024892 time: 15.117461
INFO:root:[Epoch 137] train=0.112836 val=0.912400 loss=1.006693 time: 14.796407
INFO:root:[Epoch 138] train=0.111884 val=0.905500 loss=0.976139 time: 15.403494
INFO:root:[Epoch 139] train=0.112410 val=0.910800 loss=0.988514 time: 14.966030
INFO:root:[Epoch 140] train=0.115513 val=0.913300 loss=1.034660 time: 15.053384
INFO:root:[Epoch 141] train=0.111229 val=0.911000 loss=0.977523 time: 14.956821
INFO:root:[Epoch 142] train=0.114320 val=0.906300 loss=1.019963 time: 14.857602
INFO:root:[Epoch 143] train=0.114044 val=0.903800 loss=1.015635 time: 14.830444
INFO:root:[Epoch 144] train=0.112839 val=0.908900 loss=0.989822 time: 15.130931
INFO:root:[Epoch 145] train=0.110147 val=0.917000 loss=0.959684 time: 15.058453
INFO:root:[Epoch 146] train=0.114484 val=0.912600 loss=1.026943 time: 14.844621
INFO:root:[Epoch 147] train=0.113300 val=0.913800 loss=0.994602 time: 15.094893
INFO:root:[Epoch 148] train=0.114403 val=0.914300 loss=1.022719 time: 14.894097
INFO:root:[Epoch 149] train=0.113963 val=0.910500 loss=1.005713 time: 14.873022
INFO:root:[Epoch 150] train=0.111216 val=0.915800 loss=0.989105 time: 15.094110
INFO:root:[Epoch 151] train=0.109526 val=0.921500 loss=0.972802 time: 14.955051
INFO:root:[Epoch 152] train=0.111105 val=0.914900 loss=1.009354 time: 15.293712
INFO:root:[Epoch 153] train=0.109554 val=0.921200 loss=0.981754 time: 14.976753
INFO:root:[Epoch 154] train=0.109231 val=0.916300 loss=0.963783 time: 15.004041
INFO:root:[Epoch 155] train=0.108771 val=0.920400 loss=0.962105 time: 15.020290
INFO:root:[Epoch 156] train=0.110615 val=0.919300 loss=0.994853 time: 14.880961
INFO:root:[Epoch 157] train=0.108996 val=0.920700 loss=0.969879 time: 14.949033
INFO:root:[Epoch 158] train=0.107836 val=0.921000 loss=0.961901 time: 14.871703
INFO:root:[Epoch 159] train=0.109149 val=0.921000 loss=0.977857 time: 15.360801
INFO:root:[Epoch 160] train=0.107767 val=0.916700 loss=0.963767 time: 15.100725
INFO:root:[Epoch 161] train=0.105455 val=0.920700 loss=0.921982 time: 15.068667
INFO:root:[Epoch 162] train=0.110257 val=0.918700 loss=0.990375 time: 15.464440
INFO:root:[Epoch 163] train=0.108390 val=0.920800 loss=0.962452 time: 15.746927
INFO:root:[Epoch 164] train=0.108421 val=0.919700 loss=0.957794 time: 14.732184
INFO:root:[Epoch 165] train=0.110237 val=0.918900 loss=0.998542 time: 15.005019
INFO:root:[Epoch 166] train=0.108769 val=0.919200 loss=0.975818 time: 15.129218
INFO:root:[Epoch 167] train=0.109509 val=0.919300 loss=0.986084 time: 16.160303
INFO:root:[Epoch 168] train=0.107783 val=0.919700 loss=0.959491 time: 14.881060
INFO:root:[Epoch 169] train=0.107458 val=0.919400 loss=0.955019 time: 15.077517
INFO:root:[Epoch 170] train=0.107748 val=0.917400 loss=0.960256 time: 14.953658
INFO:root:[Epoch 171] train=0.108715 val=0.922300 loss=0.978559 time: 15.649675
INFO:root:[Epoch 172] train=0.109107 val=0.921600 loss=0.981019 time: 14.980252
INFO:root:[Epoch 173] train=0.105334 val=0.921400 loss=0.925306 time: 15.068406
INFO:root:[Epoch 174] train=0.106556 val=0.919900 loss=0.948306 time: 15.104218
INFO:root:[Epoch 175] train=0.108255 val=0.918500 loss=0.966675 time: 15.691216
INFO:root:[Epoch 176] train=0.107822 val=0.921800 loss=0.963369 time: 15.955315
INFO:root:[Epoch 177] train=0.109290 val=0.920800 loss=0.983300 time: 15.067658
INFO:root:[Epoch 178] train=0.108120 val=0.916900 loss=0.962198 time: 15.011689
INFO:root:[Epoch 179] train=0.108401 val=0.920500 loss=0.982636 time: 15.009234
INFO:root:[Epoch 180] train=0.107892 val=0.920000 loss=0.965708 time: 14.986173
INFO:root:[Epoch 181] train=0.109645 val=0.920200 loss=0.989145 time: 15.023784
INFO:root:[Epoch 182] train=0.107357 val=0.920700 loss=0.962017 time: 14.954165
INFO:root:[Epoch 183] train=0.108951 val=0.920700 loss=0.981901 time: 15.139643
INFO:root:[Epoch 184] train=0.108329 val=0.920300 loss=0.972806 time: 15.790755
INFO:root:[Epoch 185] train=0.108789 val=0.922000 loss=0.986235 time: 15.999070
INFO:root:[Epoch 186] train=0.110672 val=0.916500 loss=1.000199 time: 15.758302
INFO:root:[Epoch 187] train=0.108597 val=0.918700 loss=0.974243 time: 14.950574
INFO:root:[Epoch 188] train=0.106118 val=0.918700 loss=0.945042 time: 15.025223
INFO:root:[Epoch 189] train=0.107873 val=0.918700 loss=0.974578 time: 15.883779
INFO:root:[Epoch 190] train=0.107301 val=0.920600 loss=0.964388 time: 15.198229
INFO:root:[Epoch 191] train=0.107713 val=0.918300 loss=0.972000 time: 14.946381
INFO:root:[Epoch 192] train=0.110523 val=0.919800 loss=1.005844 time: 15.109679
INFO:root:[Epoch 193] train=0.109184 val=0.918400 loss=0.992095 time: 14.888966
INFO:root:[Epoch 194] train=0.106541 val=0.920700 loss=0.947128 time: 15.148439
INFO:root:[Epoch 195] train=0.107048 val=0.921300 loss=0.956255 time: 14.777858
INFO:root:[Epoch 196] train=0.109534 val=0.922100 loss=0.983597 time: 15.063816
INFO:root:[Epoch 197] train=0.108971 val=0.921900 loss=0.978536 time: 15.178463
INFO:root:[Epoch 198] train=0.106656 val=0.920300 loss=0.945114 time: 15.516104
INFO:root:[Epoch 199] train=0.109502 val=0.921900 loss=0.983836 time: 15.993975
INFO:root:[Epoch 200] train=0.070969 val=0.928600 loss=0.124299 time: 15.121127
INFO:root:[Epoch 201] train=0.070260 val=0.926600 loss=0.114526 time: 15.125088
INFO:root:[Epoch 202] train=0.069218 val=0.927100 loss=0.109358 time: 14.883915
INFO:root:[Epoch 203] train=0.067842 val=0.927100 loss=0.105150 time: 15.057085
INFO:root:[Epoch 204] train=0.068068 val=0.927300 loss=0.104286 time: 14.838654
INFO:root:[Epoch 205] train=0.067111 val=0.927400 loss=0.101300 time: 15.253649
INFO:root:[Epoch 206] train=0.066357 val=0.926600 loss=0.098599 time: 15.429329
INFO:root:[Epoch 207] train=0.065383 val=0.927500 loss=0.095795 time: 15.012666
INFO:root:[Epoch 208] train=0.065520 val=0.927500 loss=0.094952 time: 15.354767
INFO:root:[Epoch 209] train=0.065141 val=0.926200 loss=0.093936 time: 14.987193
INFO:root:[Epoch 210] train=0.064469 val=0.927100 loss=0.092605 time: 14.865014
INFO:root:[Epoch 211] train=0.064603 val=0.927300 loss=0.091352 time: 15.615464
INFO:root:[Epoch 212] train=0.064273 val=0.927400 loss=0.091355 time: 15.942794
INFO:root:[Epoch 213] train=0.062665 val=0.925900 loss=0.088029 time: 15.889235
INFO:root:[Epoch 214] train=0.062625 val=0.925500 loss=0.087122 time: 15.874250
INFO:root:[Epoch 215] train=0.062267 val=0.926200 loss=0.085350 time: 15.674304
INFO:root:[Epoch 216] train=0.062502 val=0.927500 loss=0.085063 time: 15.710589
INFO:root:[Epoch 217] train=0.062095 val=0.925900 loss=0.085001 time: 15.791228
INFO:root:[Epoch 218] train=0.061140 val=0.927900 loss=0.082170 time: 15.170613
INFO:root:[Epoch 219] train=0.061095 val=0.926800 loss=0.081226 time: 15.135171
