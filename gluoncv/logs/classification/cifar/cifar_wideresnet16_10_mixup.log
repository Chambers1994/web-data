INFO:root:Namespace(batch_size=64, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.2, lr_decay_epoch='60,120,160', lr_decay_period=0, mode='hybrid', model='cifar_wideresnet16_10', momentum=0.9, num_epochs=220, num_gpus=2, num_workers=2, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0005)
[03:34:05] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.222895 val=0.504000 loss=1.925402 time: 26.490644
INFO:root:[Epoch 1] train=0.198322 val=0.617800 loss=1.666204 time: 25.693009
INFO:root:[Epoch 2] train=0.184176 val=0.685500 loss=1.518353 time: 25.214302
INFO:root:[Epoch 3] train=0.175506 val=0.753900 loss=1.439854 time: 25.165927
INFO:root:[Epoch 4] train=0.167673 val=0.729400 loss=1.369823 time: 25.038357
INFO:root:[Epoch 5] train=0.163037 val=0.746600 loss=1.313209 time: 25.259024
INFO:root:[Epoch 6] train=0.158959 val=0.798400 loss=1.313893 time: 25.145982
INFO:root:[Epoch 7] train=0.157149 val=0.773400 loss=1.311272 time: 25.099294
INFO:root:[Epoch 8] train=0.153489 val=0.767400 loss=1.246326 time: 25.213539
INFO:root:[Epoch 9] train=0.153250 val=0.794400 loss=1.270108 time: 25.065479
INFO:root:[Epoch 10] train=0.150639 val=0.747100 loss=1.243508 time: 25.057791
INFO:root:[Epoch 11] train=0.149493 val=0.780000 loss=1.227118 time: 24.976049
INFO:root:[Epoch 12] train=0.147787 val=0.737300 loss=1.199862 time: 25.135602
INFO:root:[Epoch 13] train=0.149407 val=0.834400 loss=1.266635 time: 25.218414
INFO:root:[Epoch 14] train=0.147621 val=0.814400 loss=1.227322 time: 25.063054
INFO:root:[Epoch 15] train=0.146113 val=0.811900 loss=1.221652 time: 25.209369
INFO:root:[Epoch 16] train=0.145589 val=0.839800 loss=1.205248 time: 25.041396
INFO:root:[Epoch 17] train=0.144566 val=0.831500 loss=1.196681 time: 25.234410
INFO:root:[Epoch 18] train=0.142857 val=0.803900 loss=1.188187 time: 25.124179
INFO:root:[Epoch 19] train=0.142678 val=0.791700 loss=1.187395 time: 25.378553
INFO:root:[Epoch 20] train=0.143305 val=0.840800 loss=1.211626 time: 25.202949
INFO:root:[Epoch 21] train=0.141934 val=0.837800 loss=1.172516 time: 25.067295
INFO:root:[Epoch 22] train=0.141956 val=0.824700 loss=1.186118 time: 25.209444
INFO:root:[Epoch 23] train=0.140295 val=0.859300 loss=1.164201 time: 25.103024
INFO:root:[Epoch 24] train=0.141470 val=0.830100 loss=1.183253 time: 25.085702
INFO:root:[Epoch 25] train=0.141354 val=0.816400 loss=1.162323 time: 25.333541
INFO:root:[Epoch 26] train=0.140978 val=0.790800 loss=1.189603 time: 25.023700
INFO:root:[Epoch 27] train=0.138569 val=0.841700 loss=1.130530 time: 24.949737
INFO:root:[Epoch 28] train=0.138835 val=0.812900 loss=1.157464 time: 25.201064
INFO:root:[Epoch 29] train=0.138180 val=0.804200 loss=1.139090 time: 25.083720
INFO:root:[Epoch 30] train=0.138729 val=0.834800 loss=1.142371 time: 25.030655
INFO:root:[Epoch 31] train=0.139632 val=0.829900 loss=1.175721 time: 25.204101
INFO:root:[Epoch 32] train=0.137588 val=0.866100 loss=1.159476 time: 25.336307
INFO:root:[Epoch 33] train=0.138630 val=0.836000 loss=1.172748 time: 25.061200
INFO:root:[Epoch 34] train=0.139526 val=0.826900 loss=1.168120 time: 24.991588
INFO:root:[Epoch 35] train=0.138049 val=0.861800 loss=1.142101 time: 25.063221
INFO:root:[Epoch 36] train=0.138300 val=0.821800 loss=1.161543 time: 24.977271
INFO:root:[Epoch 37] train=0.136713 val=0.826600 loss=1.152162 time: 25.080824
INFO:root:[Epoch 38] train=0.139102 val=0.842500 loss=1.191816 time: 25.109364
INFO:root:[Epoch 39] train=0.138500 val=0.843900 loss=1.166286 time: 25.048655
INFO:root:[Epoch 40] train=0.139067 val=0.784100 loss=1.202594 time: 25.103467
INFO:root:[Epoch 41] train=0.138244 val=0.862100 loss=1.187401 time: 25.105323
INFO:root:[Epoch 42] train=0.139120 val=0.807100 loss=1.195052 time: 25.155115
INFO:root:[Epoch 43] train=0.138616 val=0.837300 loss=1.153296 time: 25.081364
INFO:root:[Epoch 44] train=0.138198 val=0.859700 loss=1.184699 time: 25.286786
INFO:root:[Epoch 45] train=0.136629 val=0.788300 loss=1.139937 time: 25.192220
INFO:root:[Epoch 46] train=0.137621 val=0.849300 loss=1.144590 time: 25.043986
INFO:root:[Epoch 47] train=0.135131 val=0.831500 loss=1.115932 time: 25.145542
INFO:root:[Epoch 48] train=0.134809 val=0.866700 loss=1.122814 time: 25.040675
INFO:root:[Epoch 49] train=0.136024 val=0.823200 loss=1.155602 time: 25.089907
INFO:root:[Epoch 50] train=0.135923 val=0.829800 loss=1.151128 time: 25.113696
INFO:root:[Epoch 51] train=0.135046 val=0.817400 loss=1.121746 time: 25.238879
INFO:root:[Epoch 52] train=0.137176 val=0.806800 loss=1.156844 time: 25.174544
INFO:root:[Epoch 53] train=0.137559 val=0.822700 loss=1.167701 time: 25.320516
INFO:root:[Epoch 54] train=0.136585 val=0.852500 loss=1.151200 time: 25.139080
INFO:root:[Epoch 55] train=0.135106 val=0.845300 loss=1.118402 time: 25.064032
INFO:root:[Epoch 56] train=0.136380 val=0.825100 loss=1.156804 time: 25.105922
INFO:root:[Epoch 57] train=0.136064 val=0.863800 loss=1.153390 time: 25.085775
INFO:root:[Epoch 58] train=0.135276 val=0.848500 loss=1.130891 time: 25.008158
INFO:root:[Epoch 59] train=0.135430 val=0.861800 loss=1.134965 time: 25.028525
INFO:root:[Epoch 60] train=0.117364 val=0.919100 loss=1.005820 time: 25.107260
INFO:root:[Epoch 61] train=0.112830 val=0.922000 loss=0.988450 time: 25.137401
INFO:root:[Epoch 62] train=0.108826 val=0.926900 loss=0.960591 time: 25.169440
INFO:root:[Epoch 63] train=0.109459 val=0.930400 loss=0.957039 time: 25.247121
INFO:root:[Epoch 64] train=0.111509 val=0.924400 loss=1.010176 time: 25.143390
INFO:root:[Epoch 65] train=0.107923 val=0.917500 loss=0.962586 time: 25.267339
INFO:root:[Epoch 66] train=0.107578 val=0.929000 loss=0.956736 time: 25.126575
INFO:root:[Epoch 67] train=0.105548 val=0.917200 loss=0.937040 time: 25.093188
INFO:root:[Epoch 68] train=0.108263 val=0.934000 loss=0.964065 time: 25.270525
INFO:root:[Epoch 69] train=0.105588 val=0.935400 loss=0.933922 time: 25.286041
INFO:root:[Epoch 70] train=0.108462 val=0.917100 loss=0.974877 time: 25.154116
INFO:root:[Epoch 71] train=0.110472 val=0.924500 loss=0.999488 time: 25.099730
INFO:root:[Epoch 72] train=0.108202 val=0.929100 loss=0.958219 time: 25.252861
INFO:root:[Epoch 73] train=0.104549 val=0.922800 loss=0.921595 time: 25.069017
INFO:root:[Epoch 74] train=0.108755 val=0.918900 loss=0.974658 time: 25.159619
INFO:root:[Epoch 75] train=0.109126 val=0.887800 loss=0.981692 time: 25.145596
INFO:root:[Epoch 76] train=0.106336 val=0.922200 loss=0.949877 time: 25.105049
INFO:root:[Epoch 77] train=0.106644 val=0.923500 loss=0.968439 time: 25.162983
INFO:root:[Epoch 78] train=0.109614 val=0.918300 loss=0.986025 time: 25.097664
INFO:root:[Epoch 79] train=0.107718 val=0.931300 loss=0.961922 time: 25.145509
INFO:root:[Epoch 80] train=0.105325 val=0.914100 loss=0.925584 time: 25.037218
INFO:root:[Epoch 81] train=0.105920 val=0.931100 loss=0.931513 time: 25.079960
INFO:root:[Epoch 82] train=0.106611 val=0.909900 loss=0.957081 time: 25.142968
INFO:root:[Epoch 83] train=0.105865 val=0.926300 loss=0.946375 time: 25.151011
INFO:root:[Epoch 84] train=0.109496 val=0.906600 loss=0.997587 time: 25.141906
INFO:root:[Epoch 85] train=0.107934 val=0.927700 loss=0.972325 time: 25.130982
INFO:root:[Epoch 86] train=0.105251 val=0.932700 loss=0.938592 time: 25.141274
INFO:root:[Epoch 87] train=0.105851 val=0.921200 loss=0.942250 time: 25.182358
INFO:root:[Epoch 88] train=0.105464 val=0.931700 loss=0.939566 time: 25.118654
INFO:root:[Epoch 89] train=0.108467 val=0.924400 loss=0.975440 time: 25.189770
INFO:root:[Epoch 90] train=0.104638 val=0.924900 loss=0.927962 time: 25.067747
INFO:root:[Epoch 91] train=0.106987 val=0.925000 loss=0.964146 time: 25.031104
INFO:root:[Epoch 92] train=0.104766 val=0.926800 loss=0.929617 time: 25.084678
INFO:root:[Epoch 93] train=0.106685 val=0.927900 loss=0.955755 time: 25.296921
INFO:root:[Epoch 94] train=0.101349 val=0.927800 loss=0.906115 time: 25.226904
INFO:root:[Epoch 95] train=0.105402 val=0.914100 loss=0.957300 time: 25.273148
INFO:root:[Epoch 96] train=0.105967 val=0.919700 loss=0.970868 time: 25.130277
INFO:root:[Epoch 97] train=0.104726 val=0.925500 loss=0.941550 time: 25.062445
INFO:root:[Epoch 98] train=0.104362 val=0.928700 loss=0.948867 time: 25.117463
INFO:root:[Epoch 99] train=0.103589 val=0.931300 loss=0.922387 time: 25.275639
INFO:root:[Epoch 100] train=0.104331 val=0.930700 loss=0.941702 time: 25.079368
INFO:root:[Epoch 101] train=0.103804 val=0.930600 loss=0.937260 time: 25.141463
INFO:root:[Epoch 102] train=0.105054 val=0.920400 loss=0.954735 time: 25.273009
INFO:root:[Epoch 103] train=0.104245 val=0.929000 loss=0.946869 time: 25.258305
INFO:root:[Epoch 104] train=0.103772 val=0.921700 loss=0.939506 time: 25.140544
INFO:root:[Epoch 105] train=0.103258 val=0.927600 loss=0.935013 time: 25.284832
INFO:root:[Epoch 106] train=0.104327 val=0.912800 loss=0.932175 time: 25.208910
INFO:root:[Epoch 107] train=0.104350 val=0.918300 loss=0.945968 time: 25.258406
INFO:root:[Epoch 108] train=0.102378 val=0.930600 loss=0.935401 time: 25.078387
INFO:root:[Epoch 109] train=0.104191 val=0.908800 loss=0.935172 time: 25.249534
INFO:root:[Epoch 110] train=0.103816 val=0.929200 loss=0.945659 time: 25.298870
INFO:root:[Epoch 111] train=0.102318 val=0.920800 loss=0.923606 time: 25.215553
INFO:root:[Epoch 112] train=0.102021 val=0.930300 loss=0.916082 time: 25.271327
INFO:root:[Epoch 113] train=0.099255 val=0.934800 loss=0.894551 time: 25.312911
INFO:root:[Epoch 114] train=0.102849 val=0.927300 loss=0.938557 time: 25.167419
INFO:root:[Epoch 115] train=0.102076 val=0.921200 loss=0.917310 time: 25.361126
INFO:root:[Epoch 116] train=0.102656 val=0.928600 loss=0.923884 time: 25.163629
INFO:root:[Epoch 117] train=0.103302 val=0.936200 loss=0.933844 time: 25.172922
INFO:root:[Epoch 118] train=0.101459 val=0.927300 loss=0.912143 time: 25.177197
INFO:root:[Epoch 119] train=0.103181 val=0.925800 loss=0.935620 time: 25.136786
INFO:root:[Epoch 120] train=0.089489 val=0.951900 loss=0.859301 time: 25.252411
INFO:root:[Epoch 121] train=0.085197 val=0.954100 loss=0.832534 time: 25.236748
INFO:root:[Epoch 122] train=0.084549 val=0.954600 loss=0.827186 time: 25.342367
INFO:root:[Epoch 123] train=0.082148 val=0.954200 loss=0.811383 time: 25.179015
INFO:root:[Epoch 124] train=0.080272 val=0.955500 loss=0.798324 time: 25.274192
INFO:root:[Epoch 125] train=0.083346 val=0.956800 loss=0.829920 time: 25.211844
INFO:root:[Epoch 126] train=0.083473 val=0.954500 loss=0.830378 time: 25.326736
INFO:root:[Epoch 127] train=0.080381 val=0.955000 loss=0.799471 time: 25.249127
INFO:root:[Epoch 128] train=0.079444 val=0.955500 loss=0.794762 time: 25.204119
INFO:root:[Epoch 129] train=0.083584 val=0.953400 loss=0.836239 time: 25.357007
INFO:root:[Epoch 130] train=0.080143 val=0.955900 loss=0.803956 time: 25.147056
INFO:root:[Epoch 131] train=0.080555 val=0.958200 loss=0.812000 time: 25.613655
INFO:root:[Epoch 132] train=0.079238 val=0.957900 loss=0.797023 time: 25.130400
INFO:root:[Epoch 133] train=0.080242 val=0.957800 loss=0.809997 time: 25.141247
INFO:root:[Epoch 134] train=0.078513 val=0.957400 loss=0.791523 time: 25.314965
INFO:root:[Epoch 135] train=0.081227 val=0.955800 loss=0.817872 time: 25.160004
INFO:root:[Epoch 136] train=0.079906 val=0.957000 loss=0.801063 time: 25.392594
INFO:root:[Epoch 137] train=0.080432 val=0.955000 loss=0.812866 time: 25.214871
INFO:root:[Epoch 138] train=0.081779 val=0.958500 loss=0.823683 time: 25.578792
INFO:root:[Epoch 139] train=0.076812 val=0.953600 loss=0.777736 time: 25.289159
INFO:root:[Epoch 140] train=0.079299 val=0.956100 loss=0.800525 time: 25.170817
INFO:root:[Epoch 141] train=0.077933 val=0.958300 loss=0.787988 time: 25.289227
INFO:root:[Epoch 142] train=0.079192 val=0.954300 loss=0.798191 time: 25.146382
INFO:root:[Epoch 143] train=0.077213 val=0.956900 loss=0.785158 time: 25.195383
INFO:root:[Epoch 144] train=0.079239 val=0.957600 loss=0.797533 time: 25.349904
INFO:root:[Epoch 145] train=0.077756 val=0.953300 loss=0.786571 time: 25.134224
INFO:root:[Epoch 146] train=0.077431 val=0.955400 loss=0.784851 time: 25.255273
INFO:root:[Epoch 147] train=0.078214 val=0.956700 loss=0.787089 time: 25.185150
INFO:root:[Epoch 148] train=0.077899 val=0.957800 loss=0.790516 time: 25.251805
INFO:root:[Epoch 149] train=0.076512 val=0.954200 loss=0.776747 time: 25.245319
INFO:root:[Epoch 150] train=0.079327 val=0.956500 loss=0.791083 time: 25.153120
INFO:root:[Epoch 151] train=0.075709 val=0.953600 loss=0.767437 time: 25.454448
INFO:root:[Epoch 152] train=0.079448 val=0.953200 loss=0.802365 time: 25.292550
INFO:root:[Epoch 153] train=0.077805 val=0.954300 loss=0.790377 time: 25.264983
INFO:root:[Epoch 154] train=0.078141 val=0.953400 loss=0.794860 time: 25.244066
INFO:root:[Epoch 155] train=0.079494 val=0.953800 loss=0.809221 time: 25.208559
INFO:root:[Epoch 156] train=0.082295 val=0.954800 loss=0.828103 time: 25.185002
INFO:root:[Epoch 157] train=0.076316 val=0.955200 loss=0.781436 time: 25.332934
INFO:root:[Epoch 158] train=0.077460 val=0.950600 loss=0.785854 time: 25.114302
INFO:root:[Epoch 159] train=0.073844 val=0.956400 loss=0.750460 time: 25.427731
INFO:root:[Epoch 160] train=0.073361 val=0.958100 loss=0.763010 time: 25.105924
INFO:root:[Epoch 161] train=0.070650 val=0.958900 loss=0.741038 time: 25.285162
INFO:root:[Epoch 162] train=0.074078 val=0.960100 loss=0.770608 time: 25.225952
INFO:root:[Epoch 163] train=0.071009 val=0.961000 loss=0.741680 time: 25.506539
INFO:root:[Epoch 164] train=0.071464 val=0.962000 loss=0.755494 time: 25.306367
INFO:root:[Epoch 165] train=0.072270 val=0.959800 loss=0.759745 time: 25.315832
INFO:root:[Epoch 166] train=0.067542 val=0.961900 loss=0.716693 time: 25.299441
INFO:root:[Epoch 167] train=0.069964 val=0.962400 loss=0.739202 time: 25.541856
INFO:root:[Epoch 168] train=0.069178 val=0.960700 loss=0.732216 time: 25.292930
INFO:root:[Epoch 169] train=0.069409 val=0.962200 loss=0.735778 time: 25.207551
INFO:root:[Epoch 170] train=0.069388 val=0.960800 loss=0.735104 time: 25.270116
INFO:root:[Epoch 171] train=0.067690 val=0.961500 loss=0.720479 time: 25.277238
INFO:root:[Epoch 172] train=0.066211 val=0.962200 loss=0.709639 time: 25.119177
INFO:root:[Epoch 173] train=0.068246 val=0.961200 loss=0.723995 time: 25.132436
INFO:root:[Epoch 174] train=0.070051 val=0.960800 loss=0.742747 time: 25.377704
INFO:root:[Epoch 175] train=0.070139 val=0.960400 loss=0.738281 time: 25.209523
INFO:root:[Epoch 176] train=0.070527 val=0.961100 loss=0.745297 time: 25.543357
INFO:root:[Epoch 177] train=0.069560 val=0.961800 loss=0.734861 time: 25.155316
INFO:root:[Epoch 178] train=0.070341 val=0.959800 loss=0.740740 time: 25.322600
INFO:root:[Epoch 179] train=0.069730 val=0.964000 loss=0.737959 time: 25.297622
INFO:root:[Epoch 180] train=0.069948 val=0.961100 loss=0.739745 time: 25.357120
INFO:root:[Epoch 181] train=0.069964 val=0.959200 loss=0.741152 time: 25.521320
INFO:root:[Epoch 182] train=0.069099 val=0.962700 loss=0.734951 time: 25.281754
INFO:root:[Epoch 183] train=0.070901 val=0.960800 loss=0.745550 time: 25.670567
INFO:root:[Epoch 184] train=0.068806 val=0.961300 loss=0.729919 time: 25.288175
INFO:root:[Epoch 185] train=0.066435 val=0.959200 loss=0.711063 time: 25.216397
INFO:root:[Epoch 186] train=0.066959 val=0.962500 loss=0.716220 time: 25.153948
INFO:root:[Epoch 187] train=0.069792 val=0.962600 loss=0.739089 time: 25.124424
INFO:root:[Epoch 188] train=0.065125 val=0.961000 loss=0.698829 time: 25.275236
INFO:root:[Epoch 189] train=0.068419 val=0.962000 loss=0.727907 time: 25.263616
INFO:root:[Epoch 190] train=0.069531 val=0.963400 loss=0.741715 time: 25.480123
INFO:root:[Epoch 191] train=0.067103 val=0.963000 loss=0.714285 time: 25.204029
INFO:root:[Epoch 192] train=0.070199 val=0.961200 loss=0.744127 time: 25.261803
INFO:root:[Epoch 193] train=0.068572 val=0.961900 loss=0.728289 time: 25.276452
INFO:root:[Epoch 194] train=0.068496 val=0.961800 loss=0.728051 time: 25.196275
INFO:root:[Epoch 195] train=0.069679 val=0.962700 loss=0.739221 time: 25.232521
INFO:root:[Epoch 196] train=0.067711 val=0.961300 loss=0.719697 time: 25.228999
INFO:root:[Epoch 197] train=0.069653 val=0.961000 loss=0.733889 time: 25.554700
INFO:root:[Epoch 198] train=0.069997 val=0.961300 loss=0.735244 time: 25.229905
INFO:root:[Epoch 199] train=0.068116 val=0.962700 loss=0.722673 time: 25.379085
INFO:root:[Epoch 200] train=0.008452 val=0.966500 loss=0.015557 time: 25.273231
INFO:root:[Epoch 201] train=0.006855 val=0.966300 loss=0.012035 time: 25.365653
INFO:root:[Epoch 202] train=0.006113 val=0.966700 loss=0.010534 time: 25.378396
INFO:root:[Epoch 203] train=0.005638 val=0.966100 loss=0.009474 time: 25.325182
INFO:root:[Epoch 204] train=0.005368 val=0.966500 loss=0.008775 time: 25.384951
INFO:root:[Epoch 205] train=0.004877 val=0.967300 loss=0.008176 time: 25.489158
INFO:root:[Epoch 206] train=0.004852 val=0.965700 loss=0.007703 time: 25.287417
INFO:root:[Epoch 207] train=0.004427 val=0.966500 loss=0.007273 time: 25.223226
INFO:root:[Epoch 208] train=0.004480 val=0.966700 loss=0.006992 time: 25.204808
INFO:root:[Epoch 209] train=0.003957 val=0.965900 loss=0.006452 time: 25.516834
INFO:root:[Epoch 210] train=0.004089 val=0.966800 loss=0.006352 time: 25.287830
INFO:root:[Epoch 211] train=0.003658 val=0.966400 loss=0.006019 time: 25.257495
INFO:root:[Epoch 212] train=0.003561 val=0.966600 loss=0.005779 time: 25.217353
INFO:root:[Epoch 213] train=0.003562 val=0.966400 loss=0.005676 time: 25.230952
INFO:root:[Epoch 214] train=0.003497 val=0.966700 loss=0.005438 time: 25.394857
INFO:root:[Epoch 215] train=0.003436 val=0.966300 loss=0.005290 time: 25.252020
INFO:root:[Epoch 216] train=0.003332 val=0.967300 loss=0.005112 time: 25.380222
INFO:root:[Epoch 217] train=0.003087 val=0.967300 loss=0.004955 time: 25.183478
INFO:root:[Epoch 218] train=0.003203 val=0.966700 loss=0.004851 time: 25.372640
INFO:root:[Epoch 219] train=0.003025 val=0.967100 loss=0.004714 time: 25.511423
